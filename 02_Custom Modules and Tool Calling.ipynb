{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c11fc5fd-8f2c-4f7b-80dd-064441617372",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade databricks-sdk databricks-vectorsearch\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "302701a2-dd26-4702-b424-a300b8c5584b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade dspy==3.0.0b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f575134a-2ef3-4041-9b5a-9b12b600da82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dspy\n",
    "import mlflow\n",
    "# llm = dspy.LM('databricks/databricks-meta-llama-3-1-8b-instruct', cache=False)\n",
    "llm = dspy.LM('databricks/databricks-meta-llama-3-3-70b-instruct', cache=False)\n",
    "# llm = dspy.LM('databricks/databricks-claude-3-7-sonnet', cache=False)\n",
    "dspy.configure(lm=llm)\n",
    "mlflow.dspy.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f325b41-64b0-4e3e-a965-66cb6fd48c28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Section 1: Creating your own modules \n",
    "\n",
    "Now that you've created your own signatures and have learned the various ways to use modules, it's time to start building. \n",
    "\n",
    "DSPy builds upon these core concepts to give you the most flexibility when designing your applications. Because of its pure python approach, you can integrate any Python library and any Python logic within DSPy. This is where we create custom DSPy Modules.\n",
    "\n",
    "Fundamentally, a custom DSPy module looks like the structure below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3f7cdca-97ff-4a89-9842-b1b7db4f7398",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class MyProgram(dspy.Module):\n",
    "    \n",
    "    def __init__(self, ...):\n",
    "        # Define attributes and sub-modules here\n",
    "        {constructor_code}\n",
    "\n",
    "    def forward(self, input_name1, input_name2, ...):\n",
    "        # Implement your program's logic here\n",
    "        {custom_logic_code}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9ce9b44-0a2a-4f58-9834-32b365708145",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "It's very similar to Pytorch and how that framework approaches Neural Network development. It inherits dspy.Module that contains the `__call__` method. \n",
    "\n",
    "We can best illustrate the benefit of this by using python functions in conjunction with our DSPy signatures. RAG does not always have to be a function/tool call (more on this later). We can always call the LLM first, call a tool, then augment the pulled information with another LLM call. By using pure Python logic inbetween our LLM calls, we can benefit from the following: \n",
    "\n",
    "1. **Less Black Box approach**. Unlike the black box nature of an LLM, we know exactly what our Python code is doing\n",
    "2. **More reliable**. Unsure if your LLM is retrieving the right information? You can use Python to ensure you get the right information from the right tools\n",
    "3. **Smaller Language Models**. You need powerful LLMs that do function calling very well. By utilizing Python logic, we can afford to use smaller LLMs and save on cost while increasing performance\n",
    "\n",
    "Let's review one of DSPy's examples to understand how we can use signatures together and use their outputs downstream in Python logic and future LLM calls to orchestrate Agentic logic: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a71a2dbe-308b-4377-9239-230e325a01f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dspy\n",
    "######################################\n",
    "## Let's make our signatures\n",
    "######################################\n",
    "#Create the first signature that converts the question into a query\n",
    "class QueryGenerator(dspy.Signature):\n",
    "    \"\"\"Generate a query based on question to fetch relevant context\"\"\"\n",
    "    question: str = dspy.InputField()\n",
    "    query: str = dspy.OutputField()\n",
    "\n",
    "#Create the second signature that answers the original question with the added context\n",
    "class QuestionAndAnswer(dspy.Signature):\n",
    "    \"\"\"Answer the question based on the provided context\"\"\"\n",
    "    question: str = dspy.InputField()\n",
    "    context: str = dspy.InputField()\n",
    "    answer: str = dspy.OutputField()\n",
    "    identified_number: int = dspy.OutputField() \n",
    "    \n",
    "######################################\n",
    "## Now let's define a tool/python function that we will use to do too/function calling\n",
    "######################################\n",
    "\n",
    "#The tool we will use to find more context based on the user's question\n",
    "def search_wikipedia(query: str) -> list[str]:\n",
    "    \"\"\"Query ColBERT endpoint, which is a knowledge source based on wikipedia data\"\"\"\n",
    "    results = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')(query, k=1)\n",
    "    return [x[\"text\"] for x in results]\n",
    "\n",
    "######################################\n",
    "## Put it altogher in your own custom module!\n",
    "######################################\n",
    "\n",
    "class RAG(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.query_generator = dspy.Predict(QueryGenerator) #The first signature and first LLM call \n",
    "        self.answer_generator = dspy.ChainOfThought(QuestionAndAnswer) #the 2nd signature and second LLM call but using ChainOfThought this time\n",
    "\n",
    "    def forward(self, question, **kwargs):\n",
    "        with dspy.context(lm=dspy.LM('databricks/databricks-meta-llama-3-1-8b-instruct')): #We can change what LLM we use for a specific DSPy call. \n",
    "            query = self.query_generator(question=question).response #we use the first signature to convert the question from the user into a query. We use the attribute access to get only the query, not the dspy.Prediction\n",
    "        context = search_wikipedia(query)[0] #The query created by the LLM is used to serach wikipedia\n",
    "        return self.answer_generator(question=question, context=context).answer #the context retrieved from wikipedia is then sent to the 2nd inline signature call to create the final answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7d064e1-9bb8-4529-93a3-b488c48ac88d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Now let's execute the code\n",
    "rag = RAG() #We instantiate the packaged up dspy.Module \n",
    "print(rag(question=\"Is Lebron James the basketball GOAT?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c53c331-4b3f-4194-8131-1ce2b4c874a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "With the custom RAG module, we can now do two LLM calls with two distinct DSPy Signatures packaged up into one module. You can take this custom module and put it in another module and continue developing modules to put these pieces together. \n",
    "\n",
    "We did not use any Agentic Logic here. We simply used the DSPy outputs downstream to feed Python functions and other LLM calls to accomplish our task. But, in essence, we accomplished RAG, just without the vector search and Agentic reasoning part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8fb6b09-ddd9-4994-bc3e-79fdd88e1cc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 1: Make your own custom module: Stock Analyzer \n",
    "\n",
    "In this task, we will be making a stock analyzer agent. You will receive an article about a specific company and you will try to pull relevant stock information using a python function pinging the Yahoo Finance API. \n",
    "\n",
    "This Python function is provided for you below. The article to provide to the LLM is provided below as well.\n",
    "\n",
    "Your goal is create one module that accepts the article, identifies all the companies in the article, creates a list of their stock tickets, sends this list to the yahoo Python function and then sends all the results to a final LLM call to analyze the stock activity of these companies. \n",
    "\n",
    "I will leave it up to you on how you want the module to provide the final response \n",
    "\n",
    "Check your work using MLflow Traces as the created stock ticker could be incorrect\n",
    "\n",
    "Limitations: \n",
    "1. Start with Llama-8B. You should be able to accomplish this task with just llama-8b. The more powerful models will almost definitely work. If you're having trouble, feel free to bump up the model to Llama-70B\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "cb037ff7-3f02-4ef8-9f2b-5c2e07ad367e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Yahoo Finance Tool"
    }
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from typing import Dict, Optional\n",
    "\n",
    "def get_stock_data_yahoo(symbol: str) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Fetch stock data from Yahoo Finance using yfinance\n",
    "    \n",
    "    Args:\n",
    "        symbol: Stock ticker symbol (e.g., 'AAPL', 'MSFT')\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing stock data or None if error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create ticker object\n",
    "        ticker = yf.Ticker(symbol)\n",
    "        \n",
    "        # Get current info\n",
    "        info = ticker.info\n",
    "        \n",
    "        # Get recent price data\n",
    "        hist = ticker.history(period=\"1d\")\n",
    "        \n",
    "        if not hist.empty:\n",
    "            latest_price = hist['Close'].iloc[-1]\n",
    "            \n",
    "            return {\n",
    "                'symbol': symbol.upper(),\n",
    "                'price': round(latest_price, 2),\n",
    "                'company_name': info.get('longName', 'N/A'),\n",
    "                'market_cap': info.get('marketCap', 'N/A'),\n",
    "                'volume': info.get('volume', 'N/A'),\n",
    "                'previous_close': info.get('previousClose', 'N/A'),\n",
    "                'day_high': info.get('dayHigh', 'N/A'),\n",
    "                'day_low': info.get('dayLow', 'N/A')\n",
    "            }\n",
    "        else:\n",
    "            print(f\"No data found for symbol: {symbol}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {symbol}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "bce36876-68a3-4ecd-8853-f772b527401f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "article = \"\"\"\n",
    "The U.S. Space Force has awarded Boeing a $2.8 billion contract for secure satellite communications under its Evolved Strategic SATCOM (ESS) program.\n",
    "\n",
    "The program aims to enhance national defense communications with two initial satellites, with future options including expansion and Arctic capabilities, supporting operations from key facilities such as Vandenberg Space Force Base (VBG).\n",
    "\n",
    "Boeing Wins $2.8 Billion New Space Force SATCOM Contract\n",
    "By Horizon206 – Own work, CC0, https://commons.wikimedia.org/w/index.php?curid=134697393\n",
    "Boeing Secures ESS Contract\n",
    "Boeing outpaced Northrop Grumman to secure the contract, marking a critical milestone in the development of the U.S. military’s next-generation satellite communication systems. This $2.8 billion deal funds two satellites, with the U.S. Space Force retaining the option to procure two more under the broader $12 billion ESS initiative, Defense News reported.\n",
    "\n",
    "\n",
    "freestar\n",
    "Advertisement\n",
    "\n",
    "freestar\n",
    "The ESS system is designed to replace the aging Advanced Extremely High Frequency (AEHF) satellite constellation. It will provide enhanced survivability, resilience, and cybersecurity to address growing threats in space.\n",
    "\n",
    "Boeing’s proposal stood out for its innovative architecture and capacity to deliver guaranteed communication in high-threat environments.\n",
    "\n",
    "According to Kay Sears, VP and GM of Boeing’s Space, Intelligence, and Weapons Systems division, the system is engineered to meet evolving national security needs with unmatched reliability.\n",
    "\n",
    "The U.S. Space Force has awarded Boeing a $2.8 billion contract for secure satellite communications under its Evolved Strategic SATCOM (ESS) program.\n",
    "Photo: By Clemens Vasters from Viersen, Germany, Germany – Northrop Grumman B-2 Spirit, CC BY 2.0, https://commons.wikimedia.org/w/index.php?curid=50405787\n",
    "Long-Term Strategic Goals\n",
    "The contract runs through 2033 and represents a major portion of the Space Force’s long-term SATCOM evolution strategy.\n",
    "\n",
    "\n",
    "freestar\n",
    "Beyond the first satellites, ESS may include Arctic-specific capabilities to support operations in high-latitude regions, a growing area of interest for defense planners.\n",
    "\n",
    "The Space Force has also emphasized its intent to pivot toward a “family of systems” strategy. This approach will ensure incremental capability upgrades delivered on faster timelines, especially for anti-jamming and protected tactical communication functions.\n",
    "\n",
    "\n",
    "NASA HQ PHOTO | Credit: (NASA/Joel Kowsky)\n",
    "Cancellation of PTS-R and Shift in Strategy\n",
    "In a related move, the Protected Tactical SATCOM–Resilient (PTS-R) program has been officially canceled. The Space Force said this shift reflects a new strategy focusing on incremental capability delivery via existing frameworks like the Protected Tactical Waveform (PTW).\n",
    "\n",
    "While PTS-R has been discontinued, several core components of the SATCOM architecture remain in development. These include:\n",
    "\n",
    "\n",
    "freestar\n",
    "Protected Tactical SATCOM–Global\n",
    "Protected Tactical Enterprise Service\n",
    "Enterprise Management and Control\n",
    "Air Force-Army Anti-Jam Modem\n",
    "Initial prototypes of the Protected Tactical SATCOM program are expected to launch in 2026, reinforcing the broader shift to modular, adaptive systems with lower risk and reduced procurement costs.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09f568fe-d55d-4cfa-8100-6c38b0ef768a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dspy\n",
    "import json\n",
    "import mlflow\n",
    "\n",
    "llm = dspy.LM('databricks/databricks-meta-llama-3-1-8b-instruct', cache=False)\n",
    "# llm = dspy.LM('databricks/databricks-meta-llama-3-3-70b-instruct', cache=False)\n",
    "# llm = dspy.LM('databricks/databricks-claude-3-7-sonnet', cache=False)\n",
    "dspy.configure(lm=llm)\n",
    "\n",
    "class TickerIdentifier(dspy.Signature):\n",
    "    \"\"\"TODO\"\"\"\n",
    "    article: TODO\n",
    "    stock_ticker: list[dict] TODO\n",
    "\n",
    "class StockAnalysis(dspy.Signature):\n",
    "    \"\"\"TODO\"\"\"\n",
    "    stock_information: TODO\n",
    "    answer: TODO\n",
    "\n",
    "class StockAnalyzer(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.stock_list_creator = TODO\n",
    "        self.answer_generator = TODO\n",
    "\n",
    "    def forward(self, article, **kwargs):        \n",
    "        stock_list = TODO\n",
    "        yahoo_result = TODO\n",
    "        return TODO\n",
    "      \n",
    "stock_assistant = StockAnalyzer()\n",
    "print(stock_assistant(article=article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8b587d3-551e-4253-a930-0868e23bcab0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Answer Key\n",
    "import dspy\n",
    "import json\n",
    "import mlflow\n",
    "llm = dspy.LM('databricks/databricks-meta-llama-3-1-8b-instruct', cache=False)\n",
    "# llm = dspy.LM('databricks/databricks-gemma-3-12b', cache=False)\n",
    "# llm = dspy.LM('databricks/databricks-meta-llama-3-3-70b-instruct', cache=False)\n",
    "# llm = dspy.LM('databricks/databricks-claude-3-7-sonnet', cache=False)\n",
    "dspy.configure(lm=llm)\n",
    "\n",
    "class TickerIdentifier(dspy.Signature):\n",
    "    \"\"\"Read the entire article and find all companies in the article. Then create their stock ticker\"\"\"\n",
    "    article: str = dspy.InputField()\n",
    "    stock_ticker: list[dict] = dspy.OutputField(desc=\"Example: {'company': 'name', 'ticker': 'ticker_name'}\")\n",
    "\n",
    "class StockAnalysis(dspy.Signature):\n",
    "    \"\"\"Analyze the provided companies stock information and determine market health\"\"\"\n",
    "    stock_information: str = dspy.InputField()\n",
    "    answer: str = dspy.OutputField(desc=\"be descriptive and talk about each company\")\n",
    "\n",
    "class StockAnalyzer(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.stock_list_creator = dspy.ChainOfThought(TickerIdentifier)\n",
    "        # self.stock_list_creator = dspy.Predict(TickerIdentifier)\n",
    "        self.answer_generator = dspy.Predict(StockAnalysis)\n",
    "\n",
    "    def forward(self, article, **kwargs):        \n",
    "        stock_list = self.stock_list_creator(article=article).stock_ticker \n",
    "        yahoo_result = [get_stock_data_yahoo(stock['ticker']) for stock in stock_list]\n",
    "        return self.answer_generator(stock_information=yahoo_result).answer\n",
    "      \n",
    "stock_assistant = StockAnalyzer()\n",
    "print(stock_assistant(article=article))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71a2964a-b0a1-4701-b4e9-67ff84cb453b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Additional Exercise\n",
    "Consider the following: \n",
    "\n",
    "1. How would you do this without DSPy? Try to make a prompt to get the stock tickers off of the article as a list using llama-8b in the playground\n",
    "2. What's the benefit of separating out the LLM calls like this? \n",
    "3. Could you use a weaker model like Llama-8B or would you need to rely on the power of Claude or GPT-4.1 to accomplish this task?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7a8bf1d-aefd-47d4-88f6-88b991ec1309",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Section 2: Function Calling with DSPy\n",
    "\n",
    "Sometimes, you just simply don't know what kind of input is going to be provided for your Agents or GenAI applications. As such, we do need to rely on the reasoning capabilities of the LLM to determine which function to call next to find the most relevant information or execute a specific task to complete the request. \n",
    "\n",
    "Technically, you've been doing function calling in the above section. That is because function calling requires a minimum of 2 LLM calls. The process is as follows:\n",
    "1. The first call determines what function to use to answer the question. \n",
    "2. Then, the function needs to be executed. \n",
    "3. The second call takes the results of this function and completes the request\n",
    "\n",
    "In the last exercise, you took the outputs from the first LLM call, used a python function to process the outputs and then sent the processed infromation to a final LLM call. This was possible because you knew what to expect and could handle it programmatically. DSPy makes this easier by providing typing expectations from the signature. As you likely saw from the playground exercise, consistently getting the same output was likely extremely difficult when using weaker models. \n",
    "\n",
    "However, Function Calling heavily depends on the capabilities of the underlying model. You will likely be unable to accomplish function calling use cases with a model like Llama-8B unless it was specifically trained to do this well. The model needs to be able to recognize when to call a tool and know when a tool finished executing to move on to the next step.You'll see in the 8B example how it struggles to move on after an initial function call. \n",
    "\n",
    "We usually default to at least Llama-70B to accomplish function calling tasks. \n",
    "\n",
    "There are two ways to do function calling on DSPy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e924e7c-7bc1-46fe-9d2e-b89258c2d2e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Method 1: dspy.ReAct\n",
    "\n",
    "This is the easiest method and packages up the function call into a module called dspy.ReAct. It does come at the cost of some latency due to the additional LLM calls this does on your behalf. \n",
    "\n",
    "Here is an example from DSPy below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa21b783-b2ff-42c8-8a5f-1b145c069c91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "llm = dspy.LM('databricks/databricks-meta-llama-3-1-8b-instruct', cache=False)\n",
    "# llm = dspy.LM('databricks/databricks-meta-llama-3-3-70b-instruct', cache=False)\n",
    "# llm = dspy.LM('databricks/databricks-claude-3-7-sonnet', cache=False)\n",
    "dspy.configure(lm=llm)\n",
    "\n",
    "#As we saw with the math example in the first notebook, LLMs are bad at math. It's better if we could just use good old python to execute the math equation. \n",
    "def evaluate_math(expression: str) -> float:  \n",
    "    return eval(expression)\n",
    "\n",
    "def search_wikipedia(query: str) -> str:\n",
    "    results = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')(query, k=3)\n",
    "    return [x['text'] for x in results]\n",
    "\n",
    "react = dspy.ReAct(\"question -> answer\", tools=[evaluate_math, search_wikipedia])\n",
    "\n",
    "pred = react(question=\"What is 9362158 divided by the year of birth of David Gregory of Kinnairdy castle?\")\n",
    "print(pred.answer) #5761.3 is the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85964246-eb40-4eae-8c15-df2325be5710",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's walk through this example: \n",
    "1. The LLM got a question that was missing someinformation: The year of birth of David Gregory. So it decided to use the wikipedia tool first. \n",
    "2. After receiving that information, it then called the math function to do the calculation.\n",
    "3. Although it got the right answer, we can review the MLflow Trace to see that the LLM actually called the evaluate_math function multiple times as it was not getting the right answer at all. It executed this function 10 more times. \n",
    "\n",
    "When using function calling, and this applies to all LLMs, the way the function is defined and described is incredibly important. The name of the function, docstring, parameters and so forth all tell the LLMs when and how to use the function. Thus, that does require the LLM to be powerful enough to find the right function and use it. \n",
    "\n",
    "Let's try this again but using a more powerful model like Llama-70B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f152ecb-ad9c-489a-8427-04482fd50bd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# llm = dspy.LM('databricks/databricks-meta-llama-3-1-8b-instruct', cache=False)\n",
    "llm = dspy.LM('databricks/databricks-meta-llama-3-3-70b-instruct', cache=False)\n",
    "# llm = dspy.LM('databricks/databricks-claude-3-7-sonnet', cache=False)\n",
    "dspy.configure(lm=llm)\n",
    "\n",
    "#As we saw with the math example in the first notebook, LLMs are bad at math. It's better if we could just use good old python to execute the math equation. \n",
    "def evaluate_math(expression: str) -> float:  \n",
    "    return eval(expression)\n",
    "\n",
    "def search_wikipedia(query: str) -> str:\n",
    "    results = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')(query, k=3)\n",
    "    return [x['text'] for x in results]\n",
    "\n",
    "react = dspy.ReAct(\"question -> answer\", tools=[evaluate_math, search_wikipedia])\n",
    "\n",
    "pred = react(question=\"What is 9362158 divided by the year of birth of David Gregory of Kinnairdy castle?\")\n",
    "print(pred.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34c1cbd4-3c49-4656-88d5-ce3040ea59ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Great, in the MLflow Trace, we can see that switching the model GREATLY helped in calling only the necessary tools and correctly. \n",
    "\n",
    "Now let's try asking an entirely different question. For this question, we don't want to call evaluate_math at all. In a real life scenario, we simply could not predict what kind of question would be asked so we have to leave it to the LLM to decide the best course of action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1a58efc-05d3-4df1-a37d-abd8e3ffd854",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pred = react(question=\"IS Lebron James the Goat\")\n",
    "print(pred.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f08c1fc-442b-478b-b9e4-b54a15d0b521",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In the MLflow Trace, we can see evaluate_math was not called. If we had tried to code that in ourselves in a custom module, we would encounter an error or need to do extensive exception handling to make sure we accomodate for whatever input comes in. \n",
    "\n",
    "This is where Agents shine, being able to handle the uncertainty that comes in from user inputs, unstructured data and figuring out how to accomplish the task "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a76a208-91a7-4c31-9205-fc68e85664ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Method 2: Use DSPy.Tool\n",
    "\n",
    "DSPy gives you the flexibility to use dspy.Tool as a type within your signature. This returns a dspy.ToolCalls that contains what the LLM decided to send to the tool. So, you can actually check what the LLM decided to send to the Tool, adjust it if needed, then execute the tool, before sending the output to another LLM call. This is very similar to what you were doing in Section 1, except, the LLM decides what tool to call next and what that output should be. \n",
    "\n",
    "Dspy.Tool is a core component of dspy.ReAct. But, because DSPy let's you use this outside of ReAct, you lose some functionality like calling multiple functions. This is on you to implement. It has incredbily high benefits if you are very comfortable in python development. \n",
    "\n",
    "Let's see it in action below using the same example above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b6f8ac8-ffae-48f4-83ee-df635df90138",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# llm = dspy.LM('databricks/databricks-meta-llama-3-1-8b-instruct', cache=False)\n",
    "# llm = dspy.LM('databricks/databricks-meta-llama-3-3-70b-instruct', cache=False)\n",
    "llm = dspy.LM('databricks/databricks-claude-3-7-sonnet', cache=False)\n",
    "dspy.configure(lm=llm)\n",
    "                 \n",
    "#As we saw with the math example in the first notebook, LLMs are bad at math. It's better if we could just use good old python to execute the math equation. \n",
    "def evaluate_math(expression: str) -> float:  \n",
    "    return eval(expression)\n",
    "\n",
    "def search_wikipedia(query: str) -> str:\n",
    "    results = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')(query, k=3)\n",
    "    return [x['text'] for x in results]\n",
    "\n",
    "class ToolCallingQnA(dspy.Signature):\n",
    "  \"\"\"Answer the question using tools as necessary\"\"\"\n",
    "  question: str = dspy.InputField()\n",
    "  search_wikipedia: dspy.Tool = dspy.InputField()\n",
    "  evaluate_math: dspy.Tool = dspy.InputField()  \n",
    "  answer: str = dspy.OutputField()\n",
    "  tool_call_output: dspy.ToolCalls = dspy.OutputField()\n",
    "\n",
    "react = dspy.Predict(ToolCallingQnA) #Notice how we use dspy.Predict instead of dspy.ReAct\n",
    "\n",
    "pred = react(question=\"What is 9362158 divided by the year of birth of David Gregory of Kinnairdy castle?\", search_wikipedia=dspy.Tool(search_wikipedia), evaluate_math=dspy.Tool(evaluate_math))\n",
    "                      \n",
    "#Very crude execution of each function. You would need to execute this recursively until the tool calls are complete\n",
    "if pred.tool_call_output.tool_calls[0].name == 'search_wikipedia':\n",
    "  wiki_result = search_wikipedia(pred.tool_call_output.tool_calls[0].args['query'])\n",
    "  pred = react(question=f\"What is 9362158 divided by the year of birth of David Gregory of Kinnairdy castle? Wikipedia Context: {wiki_result}\", evaluate_math=dspy.Tool(evaluate_math))\n",
    "\n",
    "if pred.tool_call_output.tool_calls[0].name == 'evaluate_math':\n",
    "  math_evaluation = evaluate_math(pred.tool_call_output.tool_calls[0].args['expression'])\n",
    "  print(math_evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae44acdc-5d79-4825-bc81-ea4ef9201b9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "While a bit crude in implenetation, I'm able to control what tools it has access to after each one completes and manipulate the inputs and outputs before sending it to the next LLM call. \n",
    "\n",
    "When comparing this version with its equivalent dspy.ReAct version (earlier in cell 15) using Llama-8B, I'm able to execute this nearly 5s faster or more than double the speed than using dspy.ReAct and I avoid the excessive function calls it was making. It's something to consider if performance is a big concern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56022bcd-66f2-4d65-90d9-8200cb03ff68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 2: Make a DSPy Agent or a Function Calling Enabled Signature\n",
    "\n",
    "Given we have a search_wikipedia function as well as a yahoo stock function, let's create a Stock and Wikipedia Agent that uses both or one sources to answer questions. \n",
    "\n",
    "Your goal is to provide both as tools to find the following information: \n",
    "\n",
    "1. The same company stock information \n",
    "2. Information about said companies on wikipedia \n",
    "3. Define a new python function that uses spark.sql to write information about said companies to a delta table with the following columns: \n",
    "  \n",
    "   a. Company Name\n",
    "   \n",
    "   b. Company Stock Ticker\n",
    "   \n",
    "   c. Company Stock Summary \n",
    "   \n",
    "   d. Company Wikipedia Summary \n",
    "   \n",
    "   It's up to you if you want to let the LLM execute this query or you execute this query\n",
    "\n",
    "4. Provide an end summary stating this was all completed\n",
    "\n",
    "Limitations: Llama-70B must be used.\n",
    "\n",
    "Input example: What news is affecting Boeing's stock and financial health? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f335d32-3d06-4b24-9125-1493d27f1d5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "\n",
    "llm = dspy.LM('databricks/databricks-meta-llama-3-3-70b-instruct', cache=False)\n",
    "# llm = dspy.LM('databricks/databricks-claude-3-7-sonnet', cache=False)\n",
    "dspy.configure(lm=llm)\n",
    "\n",
    "class stock_wikipedia_agent(dspy.Signature): \n",
    "  \"\"\"TODO\"\"\"\n",
    "  question: #TODO \n",
    "  response: #TODO\n",
    "\n",
    "\n",
    "def yfinance(TODO):  #Hint this was created for you earlier \n",
    "    # TODO\n",
    "\n",
    "def search_wikipedia(TODO): #Hint use AI to make a more comprehensive wikipedia tool that actually searches wikipedia. \n",
    "    #TODO\n",
    "\n",
    "react = dspy.ReAct(stock_wikipedia_agent, tools=[yfinance, search_wikipedia])\n",
    "\n",
    "pred = react(question=\"What news is affecting Boeing's stock and financial health? \")\n",
    "print(pred.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee92172b-ed68-40ae-832d-a0f015c270f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "\n",
    "llm = dspy.LM('databricks/databricks-meta-llama-3-3-70b-instruct', cache=False)\n",
    "# llm = dspy.LM('databricks/databricks-claude-3-7-sonnet', cache=False)\n",
    "dspy.configure(lm=llm)\n",
    "\n",
    "class stock_wikipedia_agent(dspy.Signature): \n",
    "  \"\"\"A stock analysis agent\"\"\"\n",
    "  question: str = dspy.InputField() \n",
    "  response: str = dspy.OutputField()\n",
    "\n",
    "def get_stock_data_yahoo(symbol: str) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Fetch stock data from Yahoo Finance using yfinance\n",
    "    \n",
    "    Args:\n",
    "        symbol: Stock ticker symbol (e.g., 'AAPL', 'MSFT')\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing stock data or None if error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create ticker object\n",
    "        ticker = yf.Ticker(symbol)\n",
    "        \n",
    "        # Get current info\n",
    "        info = ticker.info\n",
    "        \n",
    "        # Get recent price data\n",
    "        hist = ticker.history(period=\"1d\")\n",
    "        \n",
    "        if not hist.empty:\n",
    "            latest_price = hist['Close'].iloc[-1]\n",
    "            \n",
    "            return {\n",
    "                'symbol': symbol.upper(),\n",
    "                'price': round(latest_price, 2),\n",
    "                'company_name': info.get('longName', 'N/A'),\n",
    "                'market_cap': info.get('marketCap', 'N/A'),\n",
    "                'volume': info.get('volume', 'N/A'),\n",
    "                'previous_close': info.get('previousClose', 'N/A'),\n",
    "                'day_high': info.get('dayHigh', 'N/A'),\n",
    "                'day_low': info.get('dayLow', 'N/A')\n",
    "            }\n",
    "        else:\n",
    "            print(f\"No data found for symbol: {symbol}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {symbol}: {e}\")\n",
    "        return None\n",
    "\n",
    "def search_wikipedia(query, num_results=10, get_suggestions=False):\n",
    "    \"\"\"\n",
    "    Search Wikipedia for articles matching the query.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search term\n",
    "        num_results (int): Number of search results to return (default: 10)\n",
    "        get_suggestions (bool): Whether to include search suggestions (default: False)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Search results with titles and suggestions (if requested)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if get_suggestions:\n",
    "            results, suggestion = wikipedia.search(query, results=num_results, suggestion=True)\n",
    "            return {\n",
    "                'results': results,\n",
    "                'suggestion': suggestion,\n",
    "                'query': query\n",
    "            }\n",
    "        else:\n",
    "            results = wikipedia.search(query, results=num_results)\n",
    "            return {\n",
    "                'results': results,\n",
    "                'query': query\n",
    "            }\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        return {\n",
    "            'results': e.options[:num_results],\n",
    "            'query': query,\n",
    "            'note': 'Multiple options found - showing disambiguation pages'\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'error': str(e),\n",
    "            'query': query\n",
    "        }\n",
    "\n",
    "react = dspy.ReAct(stock_wikipedia_agent, tools=[get_stock_data_yahoo, search_wikipedia])\n",
    "\n",
    "pred = react(question=\"What news is affecting Boeing's stock and financial health? \")\n",
    "print(pred.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80b35704-9524-4cbb-b216-c76d1514b43c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Task 3: Create a custom module that does function calling \n",
    "\n",
    "Now that you have a function calling signature and two tools that it can call, how would you put this into a custom module? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd0af2c3-4cd8-445a-837b-358903774036",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class stock_wikipedia_module(dspy.Module): \n",
    "  def __init__(self):\n",
    "    agent_signature = #TODO \n",
    "\n",
    "  def yfinance(self, #TODO): \n",
    "  \n",
    "  def search_wikipedia(self, #TODO):\n",
    "                       \n",
    "  def forward(#TODO): \n",
    "              \n",
    "\n",
    "run_agent = stock_wikipedia_module()\n",
    "result = run_agent(TODO=TODO)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d881ca6d-b1bc-4b2f-9f09-f7f13bef5b7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Workshop: Create a Databricks Genie Space Calling Agent\n",
    "\n",
    "For this activity, I will leave the team to create a single DSPy module that has access to two Genie Spaces. They should be unique in the data that they can query. \n",
    "\n",
    "Your goal is to create an agent that can alternate asking the two genie spaces for answers to the questions. \n",
    "\n",
    "You will need to do the following: \n",
    "1. Create two Genie Spaces either with existing data or new data\n",
    "2. Create two Python Functions that can query those two Genie Spaces. \n",
    "3. Use DSPy to do function/tool calling and use these two Genie Spaces to answer question \n",
    "4. Use MLflow Traces to test and review the accuracy of your Agent \n",
    "5. Implement some kind of memory for your Agent so that it remembers or has some kind of history it can access to know what's been talked about in the past \n",
    "\n",
    "Resources: \n",
    "1. Accessing Genie via Databricks AI bridge: https://api-docs.databricks.com/python/databricks-ai-bridge/latest/databricks_ai_bridge.html \n",
    "2. Accessing Genie via Databricks SDK: https://databricks-sdk-py.readthedocs.io/en/stable/workspace/dashboards/genie.html\n",
    "3. Genie Conversation API Documentation: https://docs.databricks.com/aws/en/genie/conversation-api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f6f2daa-683f-4352-b1ff-e10113d2179b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade git+https://github.com/stanfordnlp/dspy.git openai litellm \"mlflow[databricks]>=3.1.0\" \"databricks-connect>=16.1\" unitycatalog-ai[databricks] databricks-sdk databricks-vectorsearch\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0b9c79d-2065-44df-9086-951d4c0161f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dspy\n",
    "import mlflow\n",
    "# llm = dspy.LM('databricks/databricks-meta-llama-3-1-8b-instruct', cache=False)\n",
    "llm = dspy.LM('databricks/databricks-meta-llama-3-3-70b-instruct', cache=False)\n",
    "# llm = dspy.LM('databricks/databricks-claude-3-7-sonnet', cache=False)\n",
    "dspy.configure(lm=llm)\n",
    "mlflow.dspy.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ac8dd4e-dcde-4e3a-8191-8603768e39b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./financial.csv\")\n",
    "spark_df = spark.createDataFrame(df)\n",
    "spark_df.write.format(\"delta\").mode(\"overwrite\").option(\"delta.columnMapping.mode\", \"name\").saveAsTable('you_delta_table here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a71d1534-6590-43ee-90cb-2bd2b6a30468",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "def stock_info_genie(stock_question):\n",
    "  \"\"\"Pull stock information\"\"\"\n",
    "  w = WorkspaceClient()\n",
    "  genie_space_id = \"01f06e37644a130182f2644a3fa0fc9c\" #replace this with your genie space ID that you created\n",
    "\n",
    "  conversation = w.genie.start_conversation_and_wait(\n",
    "      space_id=genie_space_id,\n",
    "      content=stock_question\n",
    "  )\n",
    "\n",
    "  response = w.genie.get_message_attachment_query_result(\n",
    "    space_id=genie_space_id,\n",
    "    conversation_id=conversation.conversation_id,\n",
    "    message_id=conversation.message_id,\n",
    "    attachment_id=conversation.attachments[0].attachment_id\n",
    "  )\n",
    "\n",
    "  return response.statement_response.result.data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b12bae8a-9090-4e97-a91f-249bec289fb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class genie_question_answer(dspy.Signature): \n",
    "  \"\"\"answers questions about stocks\"\"\"\n",
    "  question: str = dspy.InputField() \n",
    "  response: str = dspy.OutputField() \n",
    "\n",
    "genie_llm = dspy.ReAct(genie_question_answer, tools=[stock_info_genie], max_iters=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f6589dd-63ed-44e7-8079-f9e239acc689",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = genie_llm(question=\"when did apple's stock drop by more than 5%?\")\n",
    "print(result.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a00ea5db-1a05-42ce-88a1-9da839c31518",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Example Signatures and Modules \n",
    "\n",
    "Below is a list of signatures and modules I've created for customers and demos that you can use as a reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e223a19-1e5a-4fa3-891a-6bfe5e6a65fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "these signatures were used altogether in a complete agent system from my DAIS presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2bebe940-93c3-4894-b05b-58754e2a7034",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Any\n",
    "\n",
    "class memoryHistory(dspy.BaseType):\n",
    "  history: List[dict] \n",
    "  last_message: List[str]\n",
    "  summary_so_far: str\n",
    "  # placeholder: str\n",
    "\n",
    "  def format(self) -> list[dict[str, Any]]:\n",
    "    return [\n",
    "      {\n",
    "      \"type\": \"memory\", \n",
    "      \"memory\": {\n",
    "        \"history\": self.history, \n",
    "        \"message\": self.last_message, \n",
    "        \"summary\": self.summary_so_far,\n",
    "        \"placeholder\": self.placeholder,\n",
    "        }\n",
    "      }\n",
    "      ]\n",
    "\n",
    "class text_summarizer_extraction(dspy.Signature): \n",
    "  \"\"\"Agent to summarize the ocr output and find keywords based on the original query.\"\"\"\n",
    "\n",
    "  ocr_input: str = dspy.InputField()\n",
    "  original_query: str = dspy.InputField()\n",
    "  memory_so_far: memoryHistory = dspy.InputField(desc=\"a history of the workflow so far\")\n",
    "  response: str = dspy.OutputField()\n",
    "  summary_so_far: str = dspy.OutputField()\n",
    "  keywords: str = dspy.OutputField()\n",
    "  next_agent_or_tool: Literal[\"text_processing_agent\", \"patient_lookup_genie_agent\", \"final_agent\"] = dspy.OutputField() \n",
    "\n",
    "class genie_agent(dspy.Signature): \n",
    "  \"\"\"Agent to use Databricks Genie Space to find information about a patient. It creates a question based on the provided keywords in patient_information or memory_history to query the genie_space with only the patient's name. Then, it takes the genie_output, makes a text_query based on insurance type, insurance name and keyterms like deductible found in both genie_outputs and original_query and sends the text_query to patient_insurance_lookup\"\"\"\n",
    "\n",
    "  patient_information: str = dspy.InputField(desc=\"Find the patient's name\")\n",
    "  original_query: str = dspy.InputField()\n",
    "  memory_so_far: memoryHistory = dspy.InputField(desc=\"a history of the workflow so far\")\n",
    "  genie_output: str = dspy.OutputField()\n",
    "  insurance_details: str = dspy.OutputField()\n",
    "  response: str = dspy.OutputField()\n",
    "  summary_so_far: str = dspy.OutputField()\n",
    "  deductible: str = dspy.OutputField(desc=\"this is the result of patient_insurance_lookup\")\n",
    "  next_agent_or_tool: Literal[\"text_processing_agent\", \"patient_lookup_genie_agent\", \"final_agent\"] = dspy.OutputField() \n",
    "\n",
    "class final_agent(dspy.Signature):\n",
    "  \"\"\"Agent to convert the collected information and write to a delta table based on the original_query.\"\"\" \n",
    "\n",
    "  original_query: str = dspy.InputField()\n",
    "  genie_output: list = dspy.InputField() \n",
    "  ocr_summary: str = dspy.InputField() \n",
    "  deductible: str = dspy.InputField()\n",
    "  completed_response: str = dspy.OutputField()\n",
    "\n",
    "class document_analyzer(dspy.Signature):\n",
    "  \"\"\"Agent to analyze the document provided by reviewing the outputs of the model and determining if there's enough information to go to the next agent or try analyzing the document again with a different vision model\"\"\" \n",
    "\n",
    "  vision_model_output: str = dspy.InputField()\n",
    "  response: str = dspy.OutputField() \n",
    "  next_agent_or_tool: Literal[\"text_processing_agent\", \"patient_lookup_genie_agent\", \"final_agent\"] = dspy.OutputField() \n",
    "\n",
    "class insurance_finder(dspy.Signature):\n",
    "  \"\"\"Find the relevant information based on the text_query within the image\"\"\"\n",
    "\n",
    "  image: dspy.Image = dspy.InputField()\n",
    "  text_query: str = dspy.InputField()\n",
    "  deductible: str = dspy.OutputField()\n",
    "  other_information: str = dspy.OutputField()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "510c5c58-b3b6-4207-bbc3-820bc9fe379d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "MCP Server Signature and Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a89d89a-8d3d-40b6-9cdd-465cf0d71111",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dspy\n",
    "import os\n",
    "import aiohttp\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "from fastmcp import Client\n",
    "from fastmcp.client.transports import StreamableHttpTransport\n",
    "import asyncio\n",
    "from databricks.sdk.core import Config\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "lm = dspy.LM(\"databricks/<model-serving-endpoint-name>\")\n",
    "\n",
    "# token = dbutils.secrets.get(scope=\"groq_key\", key=\"service_secret_pat\")\n",
    "\n",
    "config = Config()\n",
    "token = config.oauth_token().access_token\n",
    "#Change the URL to the URL of your MCP Server or Databricks App if a custom MCP: https://docs.databricks.com/aws/en/generative-ai/agent-framework/mcp#managed-mcp-servers\n",
    "\n",
    "transport = StreamableHttpTransport(\n",
    "    # url=\"https://genie-app-vivian-1444828305810485.aws.databricksapps.com/api/mcp/\",\n",
    "    url = \"https://telco-operations-mcp-server-1444828305810485.aws.databricksapps.com/api/mcp/\", \n",
    "    headers={\"Authorization\": f\"Bearer {token}\"}\n",
    ")\n",
    "\n",
    "class MCP_Test(dspy.Signature):\n",
    "    \"\"\"You are given a list of tools to handle user requests.\n",
    "    Use the genie-query tool to fulfill users' requests.\"\"\"\n",
    "\n",
    "    user_request: str = dspy.InputField()\n",
    "    process_result: str = dspy.OutputField()\n",
    "\n",
    "client = Client(transport)\n",
    "async def main():\n",
    "    async with client:\n",
    "        tools = await client.list_tools()\n",
    "        print(f\"Available tools: {tools}\\n\\n\")\n",
    "        dspy_tools = []\n",
    "        for tool in tools:\n",
    "            dspy_tools.append(dspy.Tool.from_mcp_tool(client, tool))\n",
    "\n",
    "        react = dspy.ReAct(MCP_Test, tools=dspy_tools)\n",
    "        result = await client.call_tool(\n",
    "            name=\"check-outage-status\",\n",
    "            # arguments={\"query\": \"List top 3 distribution centers\"}\n",
    "            arguments={\"query\": \"What is the total raw material demand by product?\"}   \n",
    "        )\n",
    "        print(result)\n",
    "        \n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a43e68e8-b158-406c-9419-457adff483a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "DSA Blog Post on interacting with a Vector Search Index and Genie Space\n",
    "\n",
    "Repo: https://github.com/databricks-solutions/databricks-blogposts/tree/main/2025-06-06-multi-modal-hls-DSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f05b949d-c491-4774-bb7f-09a983ff7a19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class image_analyzer(dspy.Signature):\n",
    "  \"\"\"review the image and genie_patient_response to answer the text_query\"\"\"\n",
    "  image: dspy.Image = dspy.InputField() \n",
    "  genie_patient_response: list = dspy.InputField()\n",
    "  text_query: str = dspy.InputField()\n",
    "  response: str = dspy.OutputField() \n",
    "  deductible: str = dspy.OutputField()\n",
    "\n",
    "class patient_information_extraction(dspy.Signature):\n",
    "  \"\"\"This class only extracts and returns information from relevant tools based on the text_query. Include relevant information from the genie_patient_response in the keywords_for_vector_search\"\"\"\n",
    "  text_query: str = dspy.InputField()\n",
    "  genie_patient_response: list = dspy.OutputField()\n",
    "  keywords_for_vector_search: str = dspy.OutputField(desc=\"string of keywords to pass to vector search\")\n",
    "\n",
    "class MultiModalPatientInsuranceAnalyzer(dspy.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.image_analyzer = dspy.Predict(image_analyzer)\n",
    "    self.patient_information_extraction = dspy.ReAct(patient_information_extraction, tools=[self.hls_patient_genie], max_iters=1)\n",
    "  \n",
    "  def process_image(self, base64_string):\n",
    "    image_data = base64.b64decode(base64_string) \n",
    "    pil_image = Image.open(io.BytesIO(image_data))\n",
    "    dspy_image = dspy.Image.from_PIL(pil_image)\n",
    "    return dspy_image\n",
    "  \n",
    "  def vector_search_for_patient_pdf(self, text_query):\n",
    "    \"\"\"Pulls matching Insurance Documents based on the text_query\"\"\"\n",
    "    client = mlflow.deployments.get_deploy_client(\"databricks\") \n",
    "    response = client.predict(\n",
    "              endpoint=model_endpoint_name,\n",
    "              inputs={\"dataframe_split\": {\n",
    "                      \"columns\": [\"text\"],\n",
    "                      \"data\": [[text_query]]\n",
    "                      }\n",
    "              }\n",
    "            )\n",
    "    text_embedding = response['predictions']['predictions']['embedding']\n",
    "    index = vs_client.get_index(endpoint_name=vector_search_endpoint_name, index_name=f\"{catalog}.{schema}.{index_name}\")\n",
    "    results = index.similarity_search(num_results=3, columns=[\"base64_image\"], query_vector=text_embedding)\n",
    "    return results['result']['data_array'][0][0]\n",
    "  \n",
    "  def hls_patient_genie(self, patient_name):\n",
    "    \"\"\"Pull Patient information based on the patient's name\"\"\"\n",
    "    w = WorkspaceClient()\n",
    "    genie_space_id = \"01effef4c7e113f9b8952cf568b49ac7\" #replace this with your genie space ID that you created\n",
    "\n",
    "    conversation = w.genie.start_conversation_and_wait(\n",
    "        space_id=genie_space_id,\n",
    "        content=f\"Find any details about {patient_name}. Limit your answer to one result.\"\n",
    "    )\n",
    "\n",
    "    response = w.genie.get_message_attachment_query_result(\n",
    "      space_id=genie_space_id,\n",
    "      conversation_id=conversation.conversation_id,\n",
    "      message_id=conversation.message_id,\n",
    "      attachment_id=conversation.attachments[0].attachment_id\n",
    "    )\n",
    "\n",
    "    return response.statement_response.result.data_array\n",
    "\n",
    "\n",
    "  def forward(self, text_query: str):\n",
    "    results = self.patient_information_extraction(text_query=text_query)\n",
    "    base64_str = self.vector_search_for_patient_pdf(text_query=results.keywords_for_vector_search)\n",
    "    dspy_image = self.process_image(base64_string=base64_str)\n",
    "    return self.image_analyzer(image=dspy_image, genie_patient_response=results.genie_patient_response, text_query=text_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f78c095-a250-4c49-ab30-3031d2df3b25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from databricks.vector_search.client import VectorSearchClient\n",
    "#make sure to pip install databricks-vectorsearch databricks-sdk\n",
    "\n",
    "vsc = VectorSearchClient(\n",
    "        workspace_url=\"https://e2-demo-field-eng.cloud.databricks.com/\",\n",
    "        personal_access_token=\"\"\n",
    "    )\n",
    "\n",
    "index = vsc.get_index(endpoint_name=VECTOR_SEARCH_ENDPOINT_NAME, index_name=vectorSearchIndexName)\n",
    "\n",
    "result = index.similarity_search(num_results=3, columns=<add the columns you want to query>, query_text=<the text you want to query)\n",
    "\n",
    "return result['result']['data_array'][0][0]"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "dbe_c75093c8-0895-475e-8c1b-6acacfe3368b",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3397375242557954,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "02_Custom Modules and Tool Calling",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
